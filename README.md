# Joint-Sparsification-and-Quantization-for-Efficient-LLM-Inference
[696DS] [Cisco] Optimizing the Accuracy-Performance Frontier: Joint Sparsification and Quantization for Efficient LLM Inference
